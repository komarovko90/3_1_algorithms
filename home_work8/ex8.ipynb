{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Обучить любую модель классификации на датасете IRIS до применения PCA (d = 2) и после него. Сравнить качество классификации по отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучать модель будем с помощью дерева решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data # значения признаков\n",
    "        self.labels = labels  # y_true\n",
    "        self.prediction = self.predict()  # y_pred\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его   \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1     # \"impurity\" - \"нечистота\", степень неопределенности\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels) # долю объектов класса в листе\n",
    "        impurity -= p ** 2 # Критерий Джини\n",
    "        \n",
    "    return impurity\n",
    "\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "def quality(left_labels, right_labels, current_gini):\n",
    "\n",
    "    # доля выборки, ушедшей в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0]) # для правого (1-p)\n",
    "    \n",
    "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels) # Функционал качества\n",
    "\n",
    "\n",
    "def find_best_split(data, labels, min_leaf):\n",
    "    \n",
    "    current_gini = gini(labels) \n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None # лучший порог разбиения\n",
    "    best_index = None # лучший индекс разбиения\n",
    "    \n",
    "    n_features = data.shape[1] # кол-во признаков\n",
    "    \n",
    "    for index in range(n_features): # проход по всем признакам\n",
    "        t_values = [row[index] for row in data] # берем столбец/признак с соотв. индексом\n",
    "        \n",
    "        for t in t_values: # проход по признаку\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t) # делаем разбиение\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue # начинаем следующий проход цикла, минуя оставшееся тело цикла\n",
    "            \n",
    "            # расчет качества текущего разбиения\n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "def build_tree(data, labels, max_depth=3, depth=0, min_leaf=4):\n",
    "# -------------------------\n",
    "# --------Мои правки-------\n",
    "# Добавление критерия остановки по глубине дерева\n",
    "\n",
    "    if max_depth == depth:\n",
    "        return Leaf(data, labels)\n",
    "# -------------------------\n",
    "    \n",
    "    quality, t, index = find_best_split(data, labels, min_leaf) # ищем лучшее разбиение\n",
    "#     print(quality, t, index)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    # неопределенность после разбиения осталась такой же как до\n",
    "    if quality == 0: # критерий останова\n",
    "#         print('leaf')\n",
    "        return Leaf(data, labels) # считаем прогноз для листьев\n",
    "\n",
    "    # если качество улучшилось, то делим дерево по лучшему разбиению\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    # -------------------------\n",
    "    # --------Мои правки-------\n",
    "    # Добавляем на вход дополнительные параметры \n",
    "    true_branch = build_tree(true_data, true_labels, max_depth, depth+1)\n",
    "    false_branch = build_tree(false_data, false_labels, max_depth, depth+1)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf): # проверка текущий узел это лист?\n",
    "        answer = node.prediction # считаем прогноз для листа\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t: # если значение признака меньше порога t\n",
    "        return classify_object(obj, node.true_branch) # рекурсия: отправляем объект в true-ветку\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch) # рекурсия: отправляем объект в false-ветку\n",
    "\n",
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree) # определяем ветки для объектов\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(X, \n",
    "                                                                                     y, \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(train_data, train_labels, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим ответы для обучающей выборки\n",
    "train_answers = predict(train_data, my_tree)\n",
    "\n",
    "# И получим ответы для тестовой выборки\n",
    "answers = predict(test_data, my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получаем следующую точность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.09523809523809"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Точность на обучающей выборке\n",
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.77777777777777"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Точность на тестовой выборке\n",
    "test_accuracy = accuracy_metric(test_labels, answers)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим метод главных компонент (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала отмасштабируем выборку\n",
    "X_ = X.astype(float)\n",
    "\n",
    "rows, cols = X_.shape\n",
    "\n",
    "# центрирование - вычитание из каждого значения среднего по строке\n",
    "means = X_.mean(0)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        X_[i, j] -= means[j]\n",
    "\n",
    "# деление каждого значения на стандартное отклонение\n",
    "std = np.std(X_, axis=0)\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        X_[j][i] /= std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственные значения в порядке убывания:\n",
      "(437.7746724797988, array([ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654]))\n",
      "(137.10457072021055, array([-0.37741762, -0.92329566, -0.02449161, -0.06694199]))\n",
      "(22.013531335697195, array([-0.71956635,  0.24438178,  0.14212637,  0.63427274]))\n",
      "(3.107225464292886, array([ 0.26128628, -0.12350962, -0.80144925,  0.52359713]))\n"
     ]
    }
   ],
   "source": [
    "# Найдем собственные векторы и собственные значения (англ. Eigenvalues)\n",
    "covariance_matrix = X_.T.dot(X_)\n",
    "eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# сформируем список кортежей (собственное значение, собственный вектор)\n",
    "eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "# и отсортируем список по убыванию собственных значений\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print('Собственные значения в порядке убывания:')\n",
    "for i in eig_pairs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля дисперсии, описываемая каждой из компонент \n",
      "[72.96244541329987, 22.850761786701778, 3.6689218892828697, 0.5178709107154814]\n",
      "Кумулятивная доля дисперсии по компонентам \n",
      "[ 72.96244541  95.8132072   99.48212909 100.        ]\n"
     ]
    }
   ],
   "source": [
    "eig_sum = sum(eig_values)\n",
    "var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Доля дисперсии, описываемая каждой из компонент \\n{var_exp}')\n",
    "\n",
    "# а теперя оценим кумулятивную (то есть накапливаемую) дисперсию при учитывании каждой из компонент\n",
    "print(f'Кумулятивная доля дисперсии по компонентам \\n{cum_var_exp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, первая главная компонента описывает почти 73% информации, а первые две в сумме - 95.8%. В то же время последняя компонента описывает всего 0.5% и может быть отброжена без страха значительных потерь в качестве нашего анализа. Мы отбросим последние две компоненты, оставив первые две."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591],\n",
       "       [-0.26934744],\n",
       "       [ 0.5804131 ],\n",
       "       [ 0.56485654]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_pairs[0][1].reshape(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица весов W:\n",
      " [[ 0.52106591 -0.37741762]\n",
      " [-0.26934744 -0.92329566]\n",
      " [ 0.5804131  -0.02449161]\n",
      " [ 0.56485654 -0.06694199]]\n"
     ]
    }
   ],
   "source": [
    "# Сформируем вектор весов из собственных векторов, соответствующих первым двум главным компонентам\n",
    "W = np.hstack((eig_pairs[0][1].reshape(4,1), eig_pairs[1][1].reshape(4,1)))\n",
    "\n",
    "print(f'Матрица весов W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем новую матрицу \"объекты-признаки\"\n",
    "# W как матрица перехода между 2мя базисами\n",
    "Z = X_.dot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим дерево решений на новой выборке Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(Z, y, \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree_2 = build_tree(train_data, train_labels, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers_z = predict(train_data, my_tree_2)\n",
    "test_answers_z = predict(test_data, my_tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_z = accuracy_metric(train_labels, train_answers_z)\n",
    "test_accuracy_z = accuracy_metric(test_labels, test_answers_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность до применение PCA:\n",
      "\ttrain:\t98.095%\n",
      "\ttest:\t97.778%\n",
      "Точность после применения PCA:\n",
      "\ttrain:\t95.238%\n",
      "\ttest:\t93.333%\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность до применение PCA:\\n\\ttrain:\\t{train_accuracy:.3f}%\\n\\ttest:\\t{test_accuracy:.3f}%')\n",
    "print(f'Точность после применения PCA:\\n\\ttrain:\\t{train_accuracy_z:.3f}%\\n\\ttest:\\t{test_accuracy_z:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим произошло понижение точности предсказания на 3-5%, что было видно при расчете доли дисперсий каждой из компонент. Потери информативности можно считать незначительными."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
