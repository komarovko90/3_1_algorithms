{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Д/з"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2,  1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)\n",
    "\n",
    "X_st = X.copy()\n",
    "X_st[1, :] = calc_std_feat(X[1, :])\n",
    "X_st[2, :] = calc_std_feat(X[2, :])\n",
    "X_st[3, :] = calc_std_feat(X[3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    err = np.sum(err)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "#   В ноль обращается выражение (1.0 - y_pred)\n",
    "    y_pred[y_pred == 1] = 1-1e-12\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 [ 0.51295149 -3.52799427 -2.30751655  6.62862132] 0.2396445385298005\n",
      "1000 [ 0.99003968 -4.4739069  -3.50184385  9.11790023] 0.20436456104822748\n",
      "1500 [ 1.36004524 -5.24499518 -4.41800057 11.08762583] 0.1824820722422445\n",
      "2000 [ 1.66377414 -5.90329171 -5.17946051 12.74798172] 0.16699488670004922\n",
      "2500 [ 1.92125494 -6.47778451 -5.83436059 14.18764762] 0.15538172117388738\n",
      "3000 [ 2.14463478 -6.98733124 -6.41032319 15.46027175] 0.14632507336930287\n",
      "3500 [ 2.34195752 -7.44521516 -6.92550556 16.60221895] 0.13904427863255084\n",
      "4000 [ 2.5188181  -7.86115182 -7.39260609 17.63945533] 0.1330451723573654\n",
      "4500 [ 2.67924745 -8.24243641 -7.82085282 18.59114884] 0.12800018223401377\n",
      "5000 [ 2.82623283 -8.59466553 -8.21714641 19.4718142 ] 0.12368408748146356\n"
     ]
    }
   ],
   "source": [
    "# Чем больше шаг я выбираю, тем меньше становится log loss, до бесконечности\n",
    "W = eval_model(X_st, y, iterations=5000, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.377832\n",
      "2: 0.020075\n",
      "3: 1.000000\n",
      "4: 0.000001\n",
      "5: 0.905178\n",
      "6: 0.072835\n",
      "7: 1.000000\n",
      "8: 0.032175\n",
      "9: 0.586265\n",
      "10: 0.999998\n"
     ]
    }
   ],
   "source": [
    "def calc_pred_proba (W, X):\n",
    "    prob = sigmoid(np.dot(W, X))\n",
    "    for i, pr in enumerate(prob):\n",
    "        print(f'{i+1}: {pr:4f}')\n",
    "    return prob\n",
    "    \n",
    "d = calc_pred_proba(W, X_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(w, X):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    y_predicted = np.zeros((1, m))\n",
    "    y_predicted = np.squeeze(y_predicted)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X))\n",
    "    \n",
    "#     За порог отнесения к тому или иному классу примем вероятность 0.5\n",
    "    for i in range(A.shape[0]):\n",
    "        if (A[i] > 0.5): \n",
    "            y_predicted[i] = 1\n",
    "        elif (A[i] <= 0.5):\n",
    "            y_predicted[i] = 0\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = calc_pred(W,X_st)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5*. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy \n",
    "def accuracy(y_pred, y):\n",
    "    return np.mean([y_pred == y])*100\n",
    "\n",
    "accuracy(y_predicted, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Матрица ошибок\n",
    "def matr_err(y_pred, y):\n",
    "    matr = np.zeros((2,2))\n",
    "    TP = [num for i, num in enumerate(y_predicted) if num == y[i] and num == 1]\n",
    "    matr[0][0] = len(TP)\n",
    "    \n",
    "    FP = [num for i, num in enumerate(y_predicted) if num != y[i] and num == 1]\n",
    "    matr[0][1] = len(FP)\n",
    "    \n",
    "    FN = [num for i, num in enumerate(y_predicted) if num != y[i] and num == 0]\n",
    "    matr[1][0] = len(FN)\n",
    "    \n",
    "    TN = [num for i, num in enumerate(y_predicted) if num == y[i] and num == 0]\n",
    "    matr[1][1] = len(TN)\n",
    "    matr = np.int64(matr)\n",
    "    return matr\n",
    "\n",
    "matr = matr_err(y_predicted, y)\n",
    "print(matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Точность\n",
    "def precision(matr_err):\n",
    "    return matr_err[0][0] / (matr_err[0][0]+matr_err[0][1])\n",
    "\n",
    "pr = precision(matr)\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Полнота\n",
    "def recall (matr_err):\n",
    "    return matr_err[0][0] / (matr_err[0][0]+matr_err[1][0])\n",
    "\n",
    "rec = recall(matr)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "def f1_score(precision, recall):\n",
    "    return 2*precision*recall/(precision+recall)\n",
    "\n",
    "f1_score(pr, rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мне кажется, что модель не может переобучиться. Понятие отступов: $M_{i}>0$, когда классификатор дает верный ответ, и $M_{i}<0$. Это говорит о том, что в целом линейная классификация уравновешивает себя, в итоге будет только уточняться."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
